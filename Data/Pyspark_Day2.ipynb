{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a56ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Pyspark demo\") \\\n",
    "    .master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "778dcf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the employee data\n",
    "rdd  = sc.textFile(\"logs.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d97922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2026-02-07 10:15:20 INFO user=101 action=login status=success',\n",
       " '2026-02-07 10:16:05 ERROR user=102 action=payment status=failed',\n",
       " '2026-02-07 10:17:11 WARN user=103 action=upload status=slow',\n",
       " '2026-02-07 10:18:50 INFO user=104 action=logout status=success',\n",
       " '2026-02-07 10:19:33 ERROR user=105 action=payment status=failed',\n",
       " 'Hello this is ETL QA Labs . ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fddda02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . 2026-02-07 10:15:20 INFO user=101 action=login status=success\n",
      "2 . 2026-02-07 10:16:05 ERROR user=102 action=payment status=failed\n",
      "3 . 2026-02-07 10:17:11 WARN user=103 action=upload status=slow\n",
      "4 . 2026-02-07 10:18:50 INFO user=104 action=logout status=success\n",
      "5 . 2026-02-07 10:19:33 ERROR user=105 action=payment status=failed\n",
      "6 . Hello this is ETL QA Labs . \n"
     ]
    }
   ],
   "source": [
    "# Read each line and append with something\n",
    "line =1\n",
    "for line_num in rdd.collect():\n",
    "    print(line,\".\",line_num)\n",
    "    line = line +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee21e164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.core.rdd.RDD"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data type of RDD\n",
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34d1e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_emp = sc.textFile(\"emp_details_source.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27e0c8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eno,ename,doj,deptno,salary',\n",
       " '1001,Arjun Sharma,2022-01-15,10,1000',\n",
       " '1002,Priya Patel,2023-03-22,20,67387',\n",
       " '1003,Ravi Kumar,2021-05-10,30,70421',\n",
       " '1004,Sneha Gupta,2020-08-25,40,68902',\n",
       " '1005,Anil Reddy,2024-02-13,50,78005',\n",
       " '1006,Neha Verma,2019-11-30,60,59843',\n",
       " '1007,Vijay Singh,2022-07-08,10,1000',\n",
       " '1008,Ananya Iyer,2021-03-15,20,74625',\n",
       " '1009,Manish Joshi,2020-12-19,30,67560',\n",
       " '1010,Simran Kaur,2023-01-11,40,68902',\n",
       " '1011,Rajesh Mehta,2021-09-01,50,62497',\n",
       " '1012,Deepika Desai,2020-06-10,60,70179',\n",
       " '1013,Shivani Sharma,2022-09-13,10,74363',\n",
       " '1014,Harish Nair,2023-04-01,20,61487',\n",
       " '1015,Komal Yadav,2021-11-23,30,61894',\n",
       " '1016,Ajay Bhatt,2020-04-25,40,70109',\n",
       " '1017,Pooja Malik,2022-02-28,50,77450',\n",
       " '1018,Raghav Joshi,2021-06-14,60,62873',\n",
       " '1019,Meera Nair,2020-09-17,10,1000',\n",
       " '1020,Krishna Rao,2023-10-02,20,2000',\n",
       " '1021,Prakash Pillai,2022-12-11,10,73569',\n",
       " '1022,Aishwarya Deshmukh,2021-07-25,20,69746',\n",
       " '1023,Vikas Soni,2020-11-15,30,60933',\n",
       " '1024,Ritu Mehra,2023-05-20,40,67801',\n",
       " '1025,Nitin Chauhan,2020-03-30,50,66948',\n",
       " '1026,Swati Kapoor,2021-10-05,60,66972',\n",
       " '1027,Harshit Kumar,2022-08-16,10,66535',\n",
       " '1028,Kanika Thakur,2020-01-10,20,67752',\n",
       " '1029,Arvind Agarwal,2023-02-18,30,70986',\n",
       " '1030,Divya Singh,2021-04-22,40,67845',\n",
       " '1031,Akash Prasad,2020-06-05,50,72594',\n",
       " '1032,Geeta Rani,2022-09-07,60,63916',\n",
       " '1033,Suresh Jain,2021-12-01,10,69234',\n",
       " '1034,Sonal Shah,2023-08-13,20,2000',\n",
       " '1035,Jayesh Bansal,2020-02-15,30,69811',\n",
       " '1036,Shweta Yadav,2021-06-03,40,63559',\n",
       " '1037,Rajendra Joshi,2023-11-19,50,73561',\n",
       " '1038,Kavita Mehta,2020-07-25,60,71892',\n",
       " '1039,Ajit Reddy,2022-04-18,10,69399',\n",
       " '1040,Pratibha Sharma,2021-09-05,20,65072',\n",
       " '1041,Subodh Tripathi,2020-05-14,30,68215',\n",
       " '1042,Sunita Gupta,2023-03-09,40,72534',\n",
       " '1043,Arvind Kumar,2021-0-22,50,70019',\n",
       " '1044,Neeraj Agarwal,2020-02-19,60,69312',\n",
       " '1045,Pankaj Joshi,2022-06-10,10,70445',\n",
       " '1046,Suman Iyer,2023-04-28,20,67751',\n",
       " '1047,Sunil Verma,2020-09-14,30,66989',\n",
       " '1048,Meenal Pandey,2021-07-03,40,66228',\n",
       " '1049,Manju Nair,2022-11-17,50,69061',\n",
       " '1050,Sandeep Yadav,2021-10-12,60,60921']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_emp.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db7d4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file using dataframe( spark) - Way 1\n",
    "df_emp_sp = spark.read.csv(\"emp_details_source.csv\",header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d382bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+------+------+\n",
      "| eno|         ename|       doj|deptno|salary|\n",
      "+----+--------------+----------+------+------+\n",
      "|1001|  Arjun Sharma|2022-01-15|    10|  1000|\n",
      "|1002|   Priya Patel|2023-03-22|    20| 67387|\n",
      "|1003|    Ravi Kumar|2021-05-10|    30| 70421|\n",
      "|1004|   Sneha Gupta|2020-08-25|    40| 68902|\n",
      "|1005|    Anil Reddy|2024-02-13|    50| 78005|\n",
      "|1006|    Neha Verma|2019-11-30|    60| 59843|\n",
      "|1007|   Vijay Singh|2022-07-08|    10|  1000|\n",
      "|1008|   Ananya Iyer|2021-03-15|    20| 74625|\n",
      "|1009|  Manish Joshi|2020-12-19|    30| 67560|\n",
      "|1010|   Simran Kaur|2023-01-11|    40| 68902|\n",
      "|1011|  Rajesh Mehta|2021-09-01|    50| 62497|\n",
      "|1012| Deepika Desai|2020-06-10|    60| 70179|\n",
      "|1013|Shivani Sharma|2022-09-13|    10| 74363|\n",
      "|1014|   Harish Nair|2023-04-01|    20| 61487|\n",
      "|1015|   Komal Yadav|2021-11-23|    30| 61894|\n",
      "|1016|    Ajay Bhatt|2020-04-25|    40| 70109|\n",
      "|1017|   Pooja Malik|2022-02-28|    50| 77450|\n",
      "|1018|  Raghav Joshi|2021-06-14|    60| 62873|\n",
      "|1019|    Meera Nair|2020-09-17|    10|  1000|\n",
      "|1020|   Krishna Rao|2023-10-02|    20|  2000|\n",
      "+----+--------------+----------+------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df = df_emp_sp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1d2df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file using pandas\n",
    "df_pd_emp = pd.read_csv(\"emp_details_source.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41b6f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file using dataframe( spark) - Way 1\n",
    "df_emp_sp = spark.read.csv(\"emp_details_source.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "887241fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+------+------+\n",
      "| eno|         ename|       doj|deptno|salary|\n",
      "+----+--------------+----------+------+------+\n",
      "|1001|  Arjun Sharma|2022-01-15|    10|  1000|\n",
      "|1002|   Priya Patel|2023-03-22|    20| 67387|\n",
      "|1003|    Ravi Kumar|2021-05-10|    30| 70421|\n",
      "|1004|   Sneha Gupta|2020-08-25|    40| 68902|\n",
      "|1005|    Anil Reddy|2024-02-13|    50| 78005|\n",
      "|1006|    Neha Verma|2019-11-30|    60| 59843|\n",
      "|1007|   Vijay Singh|2022-07-08|    10|  1000|\n",
      "|1008|   Ananya Iyer|2021-03-15|    20| 74625|\n",
      "|1009|  Manish Joshi|2020-12-19|    30| 67560|\n",
      "|1010|   Simran Kaur|2023-01-11|    40| 68902|\n",
      "|1011|  Rajesh Mehta|2021-09-01|    50| 62497|\n",
      "|1012| Deepika Desai|2020-06-10|    60| 70179|\n",
      "|1013|Shivani Sharma|2022-09-13|    10| 74363|\n",
      "|1014|   Harish Nair|2023-04-01|    20| 61487|\n",
      "|1015|   Komal Yadav|2021-11-23|    30| 61894|\n",
      "|1016|    Ajay Bhatt|2020-04-25|    40| 70109|\n",
      "|1017|   Pooja Malik|2022-02-28|    50| 77450|\n",
      "|1018|  Raghav Joshi|2021-06-14|    60| 62873|\n",
      "|1019|    Meera Nair|2020-09-17|    10|  1000|\n",
      "|1020|   Krishna Rao|2023-10-02|    20|  2000|\n",
      "+----+--------------+----------+------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_emp_sp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "750a0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file using dataframe( spark) - Way 2\n",
    "df_sp = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").csv(\"emp_details_source.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "696fdef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+------+------+\n",
      "| eno|         ename|       doj|deptno|salary|\n",
      "+----+--------------+----------+------+------+\n",
      "|1001|  Arjun Sharma|2022-01-15|    10|  1000|\n",
      "|1002|   Priya Patel|2023-03-22|    20| 67387|\n",
      "|1003|    Ravi Kumar|2021-05-10|    30| 70421|\n",
      "|1004|   Sneha Gupta|2020-08-25|    40| 68902|\n",
      "|1005|    Anil Reddy|2024-02-13|    50| 78005|\n",
      "|1006|    Neha Verma|2019-11-30|    60| 59843|\n",
      "|1007|   Vijay Singh|2022-07-08|    10|  1000|\n",
      "|1008|   Ananya Iyer|2021-03-15|    20| 74625|\n",
      "|1009|  Manish Joshi|2020-12-19|    30| 67560|\n",
      "|1010|   Simran Kaur|2023-01-11|    40| 68902|\n",
      "|1011|  Rajesh Mehta|2021-09-01|    50| 62497|\n",
      "|1012| Deepika Desai|2020-06-10|    60| 70179|\n",
      "|1013|Shivani Sharma|2022-09-13|    10| 74363|\n",
      "|1014|   Harish Nair|2023-04-01|    20| 61487|\n",
      "|1015|   Komal Yadav|2021-11-23|    30| 61894|\n",
      "|1016|    Ajay Bhatt|2020-04-25|    40| 70109|\n",
      "|1017|   Pooja Malik|2022-02-28|    50| 77450|\n",
      "|1018|  Raghav Joshi|2021-06-14|    60| 62873|\n",
      "|1019|    Meera Nair|2020-09-17|    10|  1000|\n",
      "|1020|   Krishna Rao|2023-10-02|    20|  2000|\n",
      "+----+--------------+----------+------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_sp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49d78662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+------+\n",
      "| eno|         ename|salary|\n",
      "+----+--------------+------+\n",
      "|1001|  Arjun Sharma|  1000|\n",
      "|1002|   Priya Patel| 67387|\n",
      "|1003|    Ravi Kumar| 70421|\n",
      "|1004|   Sneha Gupta| 68902|\n",
      "|1005|    Anil Reddy| 78005|\n",
      "|1006|    Neha Verma| 59843|\n",
      "|1007|   Vijay Singh|  1000|\n",
      "|1008|   Ananya Iyer| 74625|\n",
      "|1009|  Manish Joshi| 67560|\n",
      "|1010|   Simran Kaur| 68902|\n",
      "|1011|  Rajesh Mehta| 62497|\n",
      "|1012| Deepika Desai| 70179|\n",
      "|1013|Shivani Sharma| 74363|\n",
      "|1014|   Harish Nair| 61487|\n",
      "|1015|   Komal Yadav| 61894|\n",
      "|1016|    Ajay Bhatt| 70109|\n",
      "|1017|   Pooja Malik| 77450|\n",
      "|1018|  Raghav Joshi| 62873|\n",
      "|1019|    Meera Nair|  1000|\n",
      "|1020|   Krishna Rao|  2000|\n",
      "+----+--------------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Read the selected columns\n",
    "df_sp = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").csv(\"emp_details_source.csv\").select(\"eno\",\"ename\",\"salary\")\n",
    "df_sp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2e0b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+------+\n",
      "| eno|         ename|salary|\n",
      "+----+--------------+------+\n",
      "|1011|  Rajesh Mehta| 62497|\n",
      "|1012| Deepika Desai| 70179|\n",
      "|1013|Shivani Sharma| 74363|\n",
      "|1014|   Harish Nair| 61487|\n",
      "|1015|   Komal Yadav| 61894|\n",
      "+----+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read from row no 10 to 15\n",
    "df_sp = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").csv(\"emp_details_source.csv\").select(\"eno\",\"ename\",\"salary\")\n",
    "df_sp.limit(15).subtract(df_sp.limit(10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bed13f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+------+------+\n",
      "| eno|         ename|       doj|deptno|salary|\n",
      "+----+--------------+----------+------+------+\n",
      "|1001|  Arjun Sharma|2022-01-15|    10|  1000|\n",
      "|1002|   Priya Patel|2023-03-22|    20| 67387|\n",
      "|1003|    Ravi Kumar|2021-05-10|    30| 70421|\n",
      "|1004|   Sneha Gupta|2020-08-25|    40| 68902|\n",
      "|1005|    Anil Reddy|2024-02-13|    50| 78005|\n",
      "|1006|    Neha Verma|2019-11-30|    60| 59843|\n",
      "|1007|   Vijay Singh|2022-07-08|    10|  1000|\n",
      "|1008|   Ananya Iyer|2021-03-15|    20| 74625|\n",
      "|1009|  Manish Joshi|2020-12-19|    30| 67560|\n",
      "|1010|   Simran Kaur|2023-01-11|    40| 68902|\n",
      "|1011|  Rajesh Mehta|2021-09-01|    50| 62497|\n",
      "|1012| Deepika Desai|2020-06-10|    60| 70179|\n",
      "|1013|Shivani Sharma|2022-09-13|    10| 74363|\n",
      "|1014|   Harish Nair|2023-04-01|    20| 61487|\n",
      "|1015|   Komal Yadav|2021-11-23|    30| 61894|\n",
      "|1016|    Ajay Bhatt|2020-04-25|    40| 70109|\n",
      "|1017|   Pooja Malik|2022-02-28|    50| 77450|\n",
      "|1018|  Raghav Joshi|2021-06-14|    60| 62873|\n",
      "|1019|    Meera Nair|2020-09-17|    10|  1000|\n",
      "|1020|   Krishna Rao|2023-10-02|    20|  2000|\n",
      "+----+--------------+----------+------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Read the zipped file\n",
    "df_sp = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").option(\"compression\",\"gzip\").csv(\"emp_details_target.csv.gz\")\n",
    "df_sp.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7174eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data in to file\n",
    "df_sp = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").option(\"compression\",\"gzip\").csv(\"emp_details_target.csv.gz\")\n",
    "\n",
    "df_sp.write.mode(\"overwrite\").option(\"header\",\"True\").csv(\"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e0d57c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[eno: int, ename: string, doj: string, deptno: int, salary: int]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting ( in ascending order of salary)\n",
    "df_sp.orderBy(df_sp.salary.asc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c7bd177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[eno: int, ename: string, doj: string, deptno: int, salary: int]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting ( in descending order of salary)\n",
    "df_sp.orderBy(df_sp.salary.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6deecf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+----------+------+------+\n",
      "| eno|             ename|       doj|deptno|salary|\n",
      "+----+------------------+----------+------+------+\n",
      "|1001|      Arjun Sharma|2022-01-15|    10|  1000|\n",
      "|1007|       Vijay Singh|2022-07-08|    10|  1000|\n",
      "|1019|        Meera Nair|2020-09-17|    10|  1000|\n",
      "|1027|     Harshit Kumar|2022-08-16|    10| 66535|\n",
      "|1033|       Suresh Jain|2021-12-01|    10| 69234|\n",
      "|1039|        Ajit Reddy|2022-04-18|    10| 69399|\n",
      "|1045|      Pankaj Joshi|2022-06-10|    10| 70445|\n",
      "|1021|    Prakash Pillai|2022-12-11|    10| 73569|\n",
      "|1013|    Shivani Sharma|2022-09-13|    10| 74363|\n",
      "|1020|       Krishna Rao|2023-10-02|    20|  2000|\n",
      "|1034|        Sonal Shah|2023-08-13|    20|  2000|\n",
      "|1014|       Harish Nair|2023-04-01|    20| 61487|\n",
      "|1040|   Pratibha Sharma|2021-09-05|    20| 65072|\n",
      "|1002|       Priya Patel|2023-03-22|    20| 67387|\n",
      "|1046|        Suman Iyer|2023-04-28|    20| 67751|\n",
      "|1028|     Kanika Thakur|2020-01-10|    20| 67752|\n",
      "|1022|Aishwarya Deshmukh|2021-07-25|    20| 69746|\n",
      "|1008|       Ananya Iyer|2021-03-15|    20| 74625|\n",
      "|1023|        Vikas Soni|2020-11-15|    30| 60933|\n",
      "|1015|       Komal Yadav|2021-11-23|    30| 61894|\n",
      "+----+------------------+----------+------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Sorting ( in ascending order of deptno and salary)\n",
    "df_sp.orderBy(df_sp.deptno.asc(),df_sp.salary.asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29c93183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+------+------+\n",
      "| eno|         ename|       doj|deptno|salary|\n",
      "+----+--------------+----------+------+------+\n",
      "|1001|  Arjun Sharma|2022-01-15|    10|  1000|\n",
      "|1007|   Vijay Singh|2022-07-08|    10|  1000|\n",
      "|1013|Shivani Sharma|2022-09-13|    10| 74363|\n",
      "|1019|    Meera Nair|2020-09-17|    10|  1000|\n",
      "|1021|Prakash Pillai|2022-12-11|    10| 73569|\n",
      "|1027| Harshit Kumar|2022-08-16|    10| 66535|\n",
      "|1033|   Suresh Jain|2021-12-01|    10| 69234|\n",
      "|1039|    Ajit Reddy|2022-04-18|    10| 69399|\n",
      "|1045|  Pankaj Joshi|2022-06-10|    10| 70445|\n",
      "+----+--------------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter the data only for deptno = 10\n",
    "df_sp.filter(df_sp.deptno==10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f559813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+------+------+\n",
      "| eno|         ename|       doj|deptno|salary|\n",
      "+----+--------------+----------+------+------+\n",
      "|1013|Shivani Sharma|2022-09-13|    10| 74363|\n",
      "|1021|Prakash Pillai|2022-12-11|    10| 73569|\n",
      "|1027| Harshit Kumar|2022-08-16|    10| 66535|\n",
      "|1033|   Suresh Jain|2021-12-01|    10| 69234|\n",
      "|1039|    Ajit Reddy|2022-04-18|    10| 69399|\n",
      "|1045|  Pankaj Joshi|2022-06-10|    10| 70445|\n",
      "+----+--------------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter the data only for deptno = 10 and salary > 1000\n",
    "df_sp.filter((df_sp.deptno==10) & (df_sp.salary>1000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b90883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+------+------+\n",
      "| eno|         ename|       doj|deptno|salary|\n",
      "+----+--------------+----------+------+------+\n",
      "|1001|  Arjun Sharma|2022-01-15|    10|  1000|\n",
      "|1002|   Priya Patel|2023-03-22|    20| 67387|\n",
      "|1003|    Ravi Kumar|2021-05-10|    30| 70421|\n",
      "|1004|   Sneha Gupta|2020-08-25|    40| 68902|\n",
      "|1005|    Anil Reddy|2024-02-13|    50| 78005|\n",
      "|1006|    Neha Verma|2019-11-30|    60| 59843|\n",
      "|1007|   Vijay Singh|2022-07-08|    10|  1000|\n",
      "|1008|   Ananya Iyer|2021-03-15|    20| 74625|\n",
      "|1009|  Manish Joshi|2020-12-19|    30| 67560|\n",
      "|1010|   Simran Kaur|2023-01-11|    40| 68902|\n",
      "|1011|  Rajesh Mehta|2021-09-01|    50| 62497|\n",
      "|1012| Deepika Desai|2020-06-10|    60| 70179|\n",
      "|1013|Shivani Sharma|2022-09-13|    10| 74363|\n",
      "|1014|   Harish Nair|2023-04-01|    20| 61487|\n",
      "|1015|   Komal Yadav|2021-11-23|    30| 61894|\n",
      "|1016|    Ajay Bhatt|2020-04-25|    40| 70109|\n",
      "|1017|   Pooja Malik|2022-02-28|    50| 77450|\n",
      "|1018|  Raghav Joshi|2021-06-14|    60| 62873|\n",
      "|1019|    Meera Nair|2020-09-17|    10|  1000|\n",
      "|1020|   Krishna Rao|2023-10-02|    20|  2000|\n",
      "+----+--------------+----------+------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Filter the data only for deptno = 10 or salary > 1000\n",
    "df_sp.filter((df_sp.deptno==10) |(df_sp.salary>1000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c87c063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|deptno|emp_count|\n",
      "+------+---------+\n",
      "|    20|        9|\n",
      "|    40|        8|\n",
      "|    10|        9|\n",
      "|    50|        8|\n",
      "|    60|        8|\n",
      "|    30|        8|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get me the count of employees working in each department ( Grouping the data )\n",
    "df_sp.groupBy('deptno').agg(F.count(\"salary\").alias(\"emp_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b3d50b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+------+------+---------+\n",
      "| eno|         ename|       doj|deptno|salary|     city|\n",
      "+----+--------------+----------+------+------+---------+\n",
      "|1001|  Arjun Sharma|2022-01-15|    10|  1000|Bangalore|\n",
      "|1002|   Priya Patel|2023-03-22|    20| 67387|Bangalore|\n",
      "|1003|    Ravi Kumar|2021-05-10|    30| 70421|Bangalore|\n",
      "|1004|   Sneha Gupta|2020-08-25|    40| 68902|Bangalore|\n",
      "|1005|    Anil Reddy|2024-02-13|    50| 78005|     Pune|\n",
      "|1006|    Neha Verma|2019-11-30|    60| 59843|     Pune|\n",
      "|1007|   Vijay Singh|2022-07-08|    10|  1000|     Pune|\n",
      "|1008|   Ananya Iyer|2021-03-15|    20| 74625|     Pune|\n",
      "|1009|  Manish Joshi|2020-12-19|    30| 67560|     Pune|\n",
      "|1010|   Simran Kaur|2023-01-11|    40| 68902|     Pune|\n",
      "|1011|  Rajesh Mehta|2021-09-01|    50| 62497|     Pune|\n",
      "|1012| Deepika Desai|2020-06-10|    60| 70179|     NULL|\n",
      "|1013|Shivani Sharma|2022-09-13|    10| 74363|     NULL|\n",
      "|1014|   Harish Nair|2023-04-01|    20| 61487|     NULL|\n",
      "|1015|   Komal Yadav|2021-11-23|    30| 61894|     NULL|\n",
      "|1016|    Ajay Bhatt|2020-04-25|    40| 70109|     NULL|\n",
      "|1017|   Pooja Malik|2022-02-28|    50| 77450|     NULL|\n",
      "|1018|  Raghav Joshi|2021-06-14|    60| 62873|     NULL|\n",
      "|1019|    Meera Nair|2020-09-17|    10|  1000|     NULL|\n",
      "|1020|   Krishna Rao|2023-10-02|    20|  2000|     NULL|\n",
      "+----+--------------+----------+------+------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_sp = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").csv(\"emp_details_source.csv\")\n",
    "df_sp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e8a3229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------+\n",
      "|     city|deptno|emp_count|\n",
      "+---------+------+---------+\n",
      "|     NULL|    20|        4|\n",
      "|     NULL|    40|        2|\n",
      "|     NULL|    10|        4|\n",
      "|     NULL|    50|        2|\n",
      "|     NULL|    60|        3|\n",
      "|     NULL|    30|        2|\n",
      "|Bangalore|    20|        1|\n",
      "|Bangalore|    30|        1|\n",
      "|Bangalore|    40|        1|\n",
      "|Bangalore|    10|        1|\n",
      "|    Delhi|    40|        3|\n",
      "|    Delhi|    50|        3|\n",
      "|    Delhi|    30|        3|\n",
      "|    Delhi|    60|        3|\n",
      "|    Delhi|    20|        3|\n",
      "|    Delhi|    10|        3|\n",
      "|     Pune|    50|        3|\n",
      "|     Pune|    20|        1|\n",
      "|     Pune|    10|        1|\n",
      "|     Pune|    30|        2|\n",
      "+---------+------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# get me the count of employees working in each city and department ( Grouping the data )\n",
    "df_sp.groupBy('city','deptno').agg(F.count(\"salary\").alias(\"emp_count\")).orderBy(\"city\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39061e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------+-------+\n",
      "|deptno|emp_count|total_sal|max_sal|\n",
      "+------+---------+---------+-------+\n",
      "|    20|        9|   477820|  74625|\n",
      "|    40|        8|   545880|  72534|\n",
      "|    10|        9|   426545|  74363|\n",
      "|    50|        8|   570135|  78005|\n",
      "|    60|        8|   525908|  71892|\n",
      "|    30|        8|   536809|  70986|\n",
      "+------+---------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use of multiple aggregate functions\n",
    "df_sp.groupBy('deptno').agg(  F.count(\"salary\").alias(\"emp_count\"), F.sum(\"salary\").alias(\"total_sal\"), F.max(\"salary\").alias(\"max_sal\")   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e5cfc685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|deptno|emp_count|\n",
      "+------+---------+\n",
      "|    20|        9|\n",
      "|    10|        9|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Having ( filter)\n",
    "# use of multiple aggregate functions\n",
    "df_group = df_sp.groupBy('deptno').agg(F.count(\"salary\").alias(\"emp_count\"))\n",
    "df_group.filter(df_group.emp_count>8).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86727ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+------+------+---------+\n",
      "| eno|         ename|       doj|deptno|salary|     city|\n",
      "+----+--------------+----------+------+------+---------+\n",
      "|1001|  Arjun Sharma|2022-01-15|    10|  1000|Bangalore|\n",
      "|1002|   Priya Patel|2023-03-22|    20| 67387|Bangalore|\n",
      "|1003|    Ravi Kumar|2021-05-10|    30| 70421|Bangalore|\n",
      "|1004|   Sneha Gupta|2020-08-25|    40| 68902|Bangalore|\n",
      "|1005|    Anil Reddy|2024-02-13|    50| 78005|     Pune|\n",
      "|1006|    Neha Verma|2019-11-30|    60| 59843|     Pune|\n",
      "|1007|   Vijay Singh|2022-07-08|    10|  1000|     Pune|\n",
      "|1008|   Ananya Iyer|2021-03-15|    20| 74625|     Pune|\n",
      "|1009|  Manish Joshi|2020-12-19|    30| 67560|     Pune|\n",
      "|1010|   Simran Kaur|2023-01-11|    40| 68902|     Pune|\n",
      "|1011|  Rajesh Mehta|2021-09-01|    50| 62497|     Pune|\n",
      "|1012| Deepika Desai|2020-06-10|    60| 70179|     NULL|\n",
      "|1013|Shivani Sharma|2022-09-13|    10| 74363|     NULL|\n",
      "|1014|   Harish Nair|2023-04-01|    20| 61487|     NULL|\n",
      "|1015|   Komal Yadav|2021-11-23|    30| 61894|     NULL|\n",
      "|1016|    Ajay Bhatt|2020-04-25|    40| 70109|     NULL|\n",
      "|1017|   Pooja Malik|2022-02-28|    50| 77450|     NULL|\n",
      "|1018|  Raghav Joshi|2021-06-14|    60| 62873|     NULL|\n",
      "|1019|    Meera Nair|2020-09-17|    10|  1000|     NULL|\n",
      "|1020|   Krishna Rao|2023-10-02|    20|  2000|     NULL|\n",
      "+----+--------------+----------+------+------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_sp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "628c4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joins\n",
    "df_emp = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").csv(\"emp_details_source.csv\")\n",
    "df_dept = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").csv(\"department.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa40b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------------+----------+------+---------+--------+\n",
      "|deptno| eno|         ename|       doj|salary|     city|deptname|\n",
      "+------+----+--------------+----------+------+---------+--------+\n",
      "|    10|1001|  Arjun Sharma|2022-01-15|  1000|Bangalore|      IT|\n",
      "|    20|1002|   Priya Patel|2023-03-22| 67387|Bangalore|  Travel|\n",
      "|    30|1003|    Ravi Kumar|2021-05-10| 70421|Bangalore|   Forex|\n",
      "|    40|1004|   Sneha Gupta|2020-08-25| 68902|Bangalore|      HR|\n",
      "|    10|1007|   Vijay Singh|2022-07-08|  1000|     Pune|      IT|\n",
      "|    20|1008|   Ananya Iyer|2021-03-15| 74625|     Pune|  Travel|\n",
      "|    30|1009|  Manish Joshi|2020-12-19| 67560|     Pune|   Forex|\n",
      "|    40|1010|   Simran Kaur|2023-01-11| 68902|     Pune|      HR|\n",
      "|    10|1013|Shivani Sharma|2022-09-13| 74363|     NULL|      IT|\n",
      "|    20|1014|   Harish Nair|2023-04-01| 61487|     NULL|  Travel|\n",
      "|    30|1015|   Komal Yadav|2021-11-23| 61894|     NULL|   Forex|\n",
      "+------+----+--------------+----------+------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner join\n",
    "df_emp.join(df_dept,on='deptno',how='inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "976f8cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------------+----------+------+---------+--------+\n",
      "|deptno| eno|         ename|       doj|salary|     city|deptname|\n",
      "+------+----+--------------+----------+------+---------+--------+\n",
      "|    10|1001|  Arjun Sharma|2022-01-15|  1000|Bangalore|      IT|\n",
      "|    20|1002|   Priya Patel|2023-03-22| 67387|Bangalore|  Travel|\n",
      "|    30|1003|    Ravi Kumar|2021-05-10| 70421|Bangalore|   Forex|\n",
      "|    40|1004|   Sneha Gupta|2020-08-25| 68902|Bangalore|      HR|\n",
      "|    50|1005|    Anil Reddy|2024-02-13| 78005|     Pune|    NULL|\n",
      "|    60|1006|    Neha Verma|2019-11-30| 59843|     Pune|    NULL|\n",
      "|    10|1007|   Vijay Singh|2022-07-08|  1000|     Pune|      IT|\n",
      "|    20|1008|   Ananya Iyer|2021-03-15| 74625|     Pune|  Travel|\n",
      "|    30|1009|  Manish Joshi|2020-12-19| 67560|     Pune|   Forex|\n",
      "|    40|1010|   Simran Kaur|2023-01-11| 68902|     Pune|      HR|\n",
      "|    50|1011|  Rajesh Mehta|2021-09-01| 62497|     Pune|    NULL|\n",
      "|    60|1012| Deepika Desai|2020-06-10| 70179|     NULL|    NULL|\n",
      "|    10|1013|Shivani Sharma|2022-09-13| 74363|     NULL|      IT|\n",
      "|    20|1014|   Harish Nair|2023-04-01| 61487|     NULL|  Travel|\n",
      "|    30|1015|   Komal Yadav|2021-11-23| 61894|     NULL|   Forex|\n",
      "+------+----+--------------+----------+------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# left join\n",
    "df_emp.join(df_dept,on='deptno',how='left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d6b38da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------------+----------+------+---------+---------+\n",
      "|deptno| eno|         ename|       doj|salary|     city| deptname|\n",
      "+------+----+--------------+----------+------+---------+---------+\n",
      "|    10|1013|Shivani Sharma|2022-09-13| 74363|     NULL|       IT|\n",
      "|    10|1007|   Vijay Singh|2022-07-08|  1000|     Pune|       IT|\n",
      "|    10|1001|  Arjun Sharma|2022-01-15|  1000|Bangalore|       IT|\n",
      "|    20|1014|   Harish Nair|2023-04-01| 61487|     NULL|   Travel|\n",
      "|    20|1008|   Ananya Iyer|2021-03-15| 74625|     Pune|   Travel|\n",
      "|    20|1002|   Priya Patel|2023-03-22| 67387|Bangalore|   Travel|\n",
      "|    30|1015|   Komal Yadav|2021-11-23| 61894|     NULL|    Forex|\n",
      "|    30|1009|  Manish Joshi|2020-12-19| 67560|     Pune|    Forex|\n",
      "|    30|1003|    Ravi Kumar|2021-05-10| 70421|Bangalore|    Forex|\n",
      "|    40|1010|   Simran Kaur|2023-01-11| 68902|     Pune|       HR|\n",
      "|    40|1004|   Sneha Gupta|2020-08-25| 68902|Bangalore|       HR|\n",
      "|   100|NULL|          NULL|      NULL|  NULL|     NULL|Not exist|\n",
      "+------+----+--------------+----------+------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Right join\n",
    "df_emp.join(df_dept,on='deptno',how='right').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3f3f13c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------------+----------+------+---------+---------+\n",
      "|deptno| eno|         ename|       doj|salary|     city| deptname|\n",
      "+------+----+--------------+----------+------+---------+---------+\n",
      "|    10|1001|  Arjun Sharma|2022-01-15|  1000|Bangalore|       IT|\n",
      "|    10|1007|   Vijay Singh|2022-07-08|  1000|     Pune|       IT|\n",
      "|    10|1013|Shivani Sharma|2022-09-13| 74363|     NULL|       IT|\n",
      "|    20|1002|   Priya Patel|2023-03-22| 67387|Bangalore|   Travel|\n",
      "|    20|1008|   Ananya Iyer|2021-03-15| 74625|     Pune|   Travel|\n",
      "|    20|1014|   Harish Nair|2023-04-01| 61487|     NULL|   Travel|\n",
      "|    30|1003|    Ravi Kumar|2021-05-10| 70421|Bangalore|    Forex|\n",
      "|    30|1009|  Manish Joshi|2020-12-19| 67560|     Pune|    Forex|\n",
      "|    30|1015|   Komal Yadav|2021-11-23| 61894|     NULL|    Forex|\n",
      "|    40|1004|   Sneha Gupta|2020-08-25| 68902|Bangalore|       HR|\n",
      "|    40|1010|   Simran Kaur|2023-01-11| 68902|     Pune|       HR|\n",
      "|    50|1005|    Anil Reddy|2024-02-13| 78005|     Pune|     NULL|\n",
      "|    50|1011|  Rajesh Mehta|2021-09-01| 62497|     Pune|     NULL|\n",
      "|    60|1006|    Neha Verma|2019-11-30| 59843|     Pune|     NULL|\n",
      "|    60|1012| Deepika Desai|2020-06-10| 70179|     NULL|     NULL|\n",
      "|   100|NULL|          NULL|      NULL|  NULL|     NULL|Not exist|\n",
      "+------+----+--------------+----------+------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Right join\n",
    "df_emp.join(df_dept,on='deptno',how='full').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a68c5141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------------+----------+------+---------+\n",
      "|deptno| eno|         ename|       doj|salary|     city|\n",
      "+------+----+--------------+----------+------+---------+\n",
      "|    10|1001|  Arjun Sharma|2022-01-15|  1000|Bangalore|\n",
      "|    20|1002|   Priya Patel|2023-03-22| 67387|Bangalore|\n",
      "|    30|1003|    Ravi Kumar|2021-05-10| 70421|Bangalore|\n",
      "|    40|1004|   Sneha Gupta|2020-08-25| 68902|Bangalore|\n",
      "|    10|1007|   Vijay Singh|2022-07-08|  1000|     Pune|\n",
      "|    20|1008|   Ananya Iyer|2021-03-15| 74625|     Pune|\n",
      "|    30|1009|  Manish Joshi|2020-12-19| 67560|     Pune|\n",
      "|    40|1010|   Simran Kaur|2023-01-11| 68902|     Pune|\n",
      "|    10|1013|Shivani Sharma|2022-09-13| 74363|     NULL|\n",
      "|    20|1014|   Harish Nair|2023-04-01| 61487|     NULL|\n",
      "|    30|1015|   Komal Yadav|2021-11-23| 61894|     NULL|\n",
      "+------+----+--------------+----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left semi join\n",
    "df_emp.join(df_dept,on='deptno',how='left_semi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "16531abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------------+----------+------+---------+--------+\n",
      "|deptno| eno|         ename|       doj|salary|     city|deptname|\n",
      "+------+----+--------------+----------+------+---------+--------+\n",
      "|    10|1001|  Arjun Sharma|2022-01-15|  1000|Bangalore|      IT|\n",
      "|    20|1002|   Priya Patel|2023-03-22| 67387|Bangalore|  Travel|\n",
      "|    30|1003|    Ravi Kumar|2021-05-10| 70421|Bangalore|   Forex|\n",
      "|    40|1004|   Sneha Gupta|2020-08-25| 68902|Bangalore|      HR|\n",
      "|    10|1007|   Vijay Singh|2022-07-08|  1000|     Pune|      IT|\n",
      "|    20|1008|   Ananya Iyer|2021-03-15| 74625|     Pune|  Travel|\n",
      "|    30|1009|  Manish Joshi|2020-12-19| 67560|     Pune|   Forex|\n",
      "|    40|1010|   Simran Kaur|2023-01-11| 68902|     Pune|      HR|\n",
      "|    10|1013|Shivani Sharma|2022-09-13| 74363|     NULL|      IT|\n",
      "|    20|1014|   Harish Nair|2023-04-01| 61487|     NULL|  Travel|\n",
      "|    30|1015|   Komal Yadav|2021-11-23| 61894|     NULL|   Forex|\n",
      "+------+----+--------------+----------+------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.join(df_dept,on='deptno',how='inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "749cd45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------------+----------+------+----+\n",
      "|deptno| eno|        ename|       doj|salary|city|\n",
      "+------+----+-------------+----------+------+----+\n",
      "|    50|1005|   Anil Reddy|2024-02-13| 78005|Pune|\n",
      "|    60|1006|   Neha Verma|2019-11-30| 59843|Pune|\n",
      "|    50|1011| Rajesh Mehta|2021-09-01| 62497|Pune|\n",
      "|    60|1012|Deepika Desai|2020-06-10| 70179|NULL|\n",
      "+------+----+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left anti join\n",
    "df_emp.join(df_dept,on='deptno',how='left_anti').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c8b6ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set oprators in pyspark\n",
    "df_dept = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").csv(\"department.csv\")\n",
    "df_dept1 = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").csv(\"department1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dea4c2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|deptno|deptname|\n",
      "+------+--------+\n",
      "|    10|      IT|\n",
      "|    20|  Travel|\n",
      "|    30|   Forex|\n",
      "|    40|      HR|\n",
      "|    80|  Parent|\n",
      "|    90|   Child|\n",
      "|    10|      IT|\n",
      "|    20|  Travel|\n",
      "|    30|   Forex|\n",
      "|    40|      HR|\n",
      "|    50|   Admin|\n",
      "|    60|Commerce|\n",
      "|    70|  Health|\n",
      "+------+--------+\n",
      "\n",
      "+------+--------+\n",
      "|deptno|deptname|\n",
      "+------+--------+\n",
      "|    10|      IT|\n",
      "|    20|  Travel|\n",
      "|    30|   Forex|\n",
      "|    40|      HR|\n",
      "|    80|  Parent|\n",
      "|    90|   Child|\n",
      "|    10|      IT|\n",
      "|    20|  Travel|\n",
      "|    30|   Forex|\n",
      "|    40|      HR|\n",
      "|    50|   Admin|\n",
      "|    60|Commerce|\n",
      "|    70|  Health|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Union\n",
    "df_dept.union(df_dept1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "59d94a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|deptno|deptname|\n",
      "+------+--------+\n",
      "|    10|      IT|\n",
      "|    20|  Travel|\n",
      "|    30|   Forex|\n",
      "|    40|      HR|\n",
      "|    50|   Admin|\n",
      "|    60|Commerce|\n",
      "|    70|  Health|\n",
      "|    80|  Parent|\n",
      "|    90|   Child|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dept.unionAll(df_dept1).distinct().orderBy(df_dept.deptno).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "24b6a211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|deptno|deptname|\n",
      "+------+--------+\n",
      "|    10|      IT|\n",
      "|    30|   Forex|\n",
      "|    20|  Travel|\n",
      "|    40|      HR|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Intersection\n",
    "df_dept.intersect(df_dept1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5327e547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|deptno|deptname|\n",
      "+------+--------+\n",
      "|    90|   Child|\n",
      "|    80|  Parent|\n",
      "+------+--------+\n",
      "\n",
      "+------+--------+\n",
      "|deptno|deptname|\n",
      "+------+--------+\n",
      "|    50|   Admin|\n",
      "|    60|Commerce|\n",
      "|    70|  Health|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Except( minus)\n",
    "df_dept.exceptAll(df_dept1).show()\n",
    "df_dept1.exceptAll(df_dept).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d298a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept = spark.read.option(\"header\",\"True\").option(\"inferSchema\",\"True\").option(\"delimiter\",\",\").csv(\"emp_details_source.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "965df57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = df_dept.filter(df_dept.salary>50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0e0c2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf2 = tf1.groupby('deptno').agg(F.count(\"salary\").alias(\"emp_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d4b5f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf3 = tdf2.filter(tdf2.emp_count>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "63d48243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|deptno|emp_count|\n",
      "+------+---------+\n",
      "|    20|        3|\n",
      "|    40|        2|\n",
      "|    50|        2|\n",
      "|    60|        2|\n",
      "|    30|        3|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "db89f599",
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkAttributeError",
     "evalue": "[ATTRIBUTE_NOT_SUPPORTED] Attribute `emp_count` is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPySparkAttributeError\u001b[0m                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [121]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_dept\u001b[38;5;241m.\u001b[39mfilter(df_dept\u001b[38;5;241m.\u001b[39msalary\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m50000\u001b[39m)\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeptno\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg(F\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memp_count\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mfilter(\u001b[43mdf_dept\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memp_count\u001b[49m\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pyspark\\sql\\classic\\dataframe.py:971\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m--> 971\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkAttributeError(\n\u001b[0;32m    972\u001b[0m             errorClass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mATTRIBUTE_NOT_SUPPORTED\u001b[39m\u001b[38;5;124m\"\u001b[39m, messageParameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattr_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: name}\n\u001b[0;32m    973\u001b[0m         )\n\u001b[0;32m    974\u001b[0m     jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[1;31mPySparkAttributeError\u001b[0m: [ATTRIBUTE_NOT_SUPPORTED] Attribute `emp_count` is not supported."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762f8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
